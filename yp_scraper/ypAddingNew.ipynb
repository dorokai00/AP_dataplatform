{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver ## Driver for Firefox, Chrome, Edge, etc.\n",
    "from selenium.webdriver.common.by import By # Mode of locating html elements: ID, CSS_SELECTOR, XPATH, ...\n",
    "from selenium.webdriver.support.select import Select\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FUNCTIONS SET UP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_search():\n",
    "    #go to start page and make into soup html obj\n",
    "    url = \"https://www.gelbeseiten.de/branchenbuch/staedte/schleswig-holstein/landkreise\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    #find all counties\n",
    "    lk = soup.find_all(class_=\"filterlist__item\")\n",
    "    landkreis_stack = [] #create empty stack to put counties into (not a stack tho)\n",
    "    for e in lk:\n",
    "        county_refined = e.text.lower()\n",
    "        county_refined = county_refined.strip()\n",
    "        landkreis_stack.append(county_refined)\n",
    "\n",
    "    return landkreis_stack\n",
    "\n",
    "\n",
    "def city_search(county_in_question):\n",
    "    #pass relevant counties as argument and get its cities\n",
    "    url = f\"https://www.gelbeseiten.de/branchenbuch/staedte/schleswig-holstein/{county_in_question}\"\n",
    "    #print(url) #remove or comment later\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    places = soup.find_all(class_=\"boxteaser__title\")\n",
    "\n",
    "    city_stack = []\n",
    "    for e in places:\n",
    "        city_stack.append(e.text.lower()) #append all city names (for one county)\n",
    "\n",
    "    return city_stack\n",
    "\n",
    "\n",
    "def set_up_mongo(client_str,database_str,collection_str):\n",
    "    client = MongoClient(client_str) #connect to mongodb client\n",
    "    db = client[database_str] #connect to database\n",
    "\n",
    "    existing_collections = db.list_collection_names() #check that dbs collections\n",
    "    if collection_str not in existing_collections:\n",
    "        db.create_collection(collection_str) #create collection if needed\n",
    "\n",
    "    my_collection = db[collection_str] #connect to collection\n",
    "\n",
    "    return my_collection\n",
    "\n",
    "\n",
    "def get_business_per_location(collection,city):\n",
    "    #get all businesses yellow page link as its unique identifier from mongodb\n",
    "    #all_buisness = [x['@id'] for x in collection.find({},{'_id':0,'@id':1})] #get the yellow page link of all businesses in database\n",
    "    available_buiz = [x['@id'] for x in collection.find({'address.addressLocality':f'{city}'},{'_id':0,'@id':1})] #get the yellow page link of all businesses in database\n",
    "    return available_buiz\n",
    "\n",
    "#### get the links from the businesses which are like behind the 'newly added' link\n",
    "def get_new_additions(county,city):\n",
    "    #so for each county/city\n",
    "    url = f'https://www.gelbeseiten.de/branchenbuch/staedte/schleswig-holstein/{county}/{city}/unternehmen'\n",
    "    url = urllib.parse.quote(url, safe=':/')\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #go to the all new business section and collect all links on there\n",
    "    links = soup.find_all('a',class_='link')\n",
    "    all_links = []\n",
    "    for elm in links:\n",
    "        link_yp = elm.get(\"href\") #get the yellowpage link for 1 buisness\n",
    "        #only keep relevant links\n",
    "        if link_yp.startswith('https://www.gelbeseiten.de/gsbiz'):\n",
    "            all_links.append(link_yp)\n",
    "    \n",
    "    print(f\"got all them links! #no: {len(all_links)}. here they are: \",all_links)\n",
    "\n",
    "    return all_links\n",
    "\n",
    "#### collect business info as before\n",
    "def collect_buisness_info_nittyGritty(my_buisnesses,my_list):\n",
    "    for elm in my_buisnesses:\n",
    "        time.sleep(1)\n",
    "        #for each element in list of all buisness per branch (in one city)\n",
    "        try:\n",
    "            html = requests.get(elm).text #go there\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            json_soup = soup.find_all(type=\"application/ld+json\") #same as above\n",
    "            if len(json_soup) > 0:\n",
    "                e = json_soup[len(json_soup)-1] #seems to be in last element always (i hope)\n",
    "                e = e.text\n",
    "                data = json.loads(e)\n",
    "                #print(data, type(data))\n",
    "            else:\n",
    "                data = {\"business\":elm, \"message\":\"failure - this buisness seems to not be available in json format\"}\n",
    "        except Exception as e:\n",
    "                error_type = type(e).__name__  # Get the name of the exception\n",
    "                error_message = str(e)         # Get the error message\n",
    "                data = {\"website\":elm, \"error_type\":error_type, \"error_message\":error_message}        \n",
    "        \n",
    "        my_list.append(data)\n",
    "\n",
    "\n",
    "#### see if newly found yp links are already in database\n",
    "def check_if_existing(old,new):\n",
    "    actually_new = []\n",
    "    for e in new:\n",
    "        if e not in old:\n",
    "            actually_new.append(e)\n",
    "\n",
    "    print(f\"check if some new buiz was found, #no {len(actually_new)}\", actually_new)\n",
    "\n",
    "    return actually_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## the actual adding to\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mongo = set_up_mongo('mongodb://localhost:27017/','d2v2','yellow_pages')\n",
    "\n",
    "lk_stack = county_search()\n",
    "for lk in lk_stack:\n",
    "    city = city_search(lk)\n",
    "    pattern = r\"[)(]\"\n",
    "    city_chic = [re.sub(pattern, '', e) for e in city]\n",
    "    for c in city_chic:\n",
    "        new_data = []\n",
    "        possible_new_buizz = get_new_additions(lk,c) #scrape yp data\n",
    "        old_buizz = get_business_per_location(my_mongo,c) #query mongodb database\n",
    "        new_buizz = check_if_existing(old_buizz,possible_new_buizz)\n",
    "        collect_buisness_info_nittyGritty(new_buizz,new_data)\n",
    "        if new_data != []:\n",
    "            my_mongo.insert_many(new_data)\n",
    "            print(f\"data inserted for {lk}: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kfs in [\"kiel\",\"lübeck\",\"flensburg\",\"neumünster\"]:\n",
    "    possible_new_buizz = get_new_additions(\"kreisfrei\",c)\n",
    "    old_buizz = get_business_per_location(my_mongo,c) #query mongodb database\n",
    "    new_buizz = check_if_existing(old_buizz,possible_new_buizz)\n",
    "    collect_buisness_info_nittyGritty(new_buizz,new_data)\n",
    "    if new_data != []:\n",
    "            my_mongo.insert_many(new_data)\n",
    "            print(f\"data inserted for {c}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

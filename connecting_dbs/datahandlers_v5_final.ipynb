{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "from pymongo import MongoClient\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely import from_wkt\n",
    "import json\n",
    "from thefuzz import fuzz\n",
    "from datetime import timedelta\n",
    "from bson import ObjectId\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data base handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBHandlers(ABC):\n",
    "\n",
    "    @abstractmethod \n",
    "    def connect_db(self,Client,client_str,db_str,coll_str): \n",
    "        client = Client(client_str) #connect to mongodb client\n",
    "        db = client[db_str] #connect to database\n",
    "        existing_collections = db.list_collection_names() #check that dbs collections\n",
    "        if coll_str not in existing_collections:\n",
    "            db.create_collection(coll_str) #create collection if needed\n",
    "        self.collection = db[coll_str] #connect to collection\n",
    "\n",
    "    @abstractmethod\n",
    "    def design_query_dict(self):\n",
    "        query_terms = [{},{}] # {\"$or\":[{},{}]} returns everything\n",
    "        return query_terms\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def retrieve_data(self):\n",
    "        self.data = [elem for elem in self.collection.find(self.query_dict)]\n",
    "\n",
    "    @abstractmethod\n",
    "    def check_click_radius(self,click_point,radius,data):\n",
    "        in_radius = []\n",
    "        for e in data:\n",
    "            try:\n",
    "                #try like this because of naming irregularities with yp and osm data\n",
    "                try:\n",
    "                    lat, lon = e[\"lat\"],e[\"lon\"]\n",
    "                except KeyError:\n",
    "                    lat, lon = e[\"latitude\"],e[\"longitude\"]\n",
    "                other_point = (lat,lon)\n",
    "                dist = geodesic(click_point, other_point).km\n",
    "                if dist < radius:\n",
    "                    in_radius.append(e)\n",
    "            except:\n",
    "                pass\n",
    "        self.results = in_radius\n",
    "\n",
    "    @abstractmethod\n",
    "    def click_polygon(self,click_point, data):\n",
    "        #get adminlevel=6 boundaries data\n",
    "        df = pd.read_csv(\"sh_boundaries_6.csv\")\n",
    "        df = df[[\"name\",\"geometry\"]]\n",
    "        df[\"geometry\"] = df[\"geometry\"].apply(from_wkt)\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        gdf.set_crs(\"EPSG:4326\",inplace=True)\n",
    "\n",
    "        #reorder for check\n",
    "        click_point = [click_point]\n",
    "        reordered_point = [(lon, lat) for lat, lon in click_point]\n",
    "        reordered_point = Point(reordered_point)\n",
    "\n",
    "        #check for intersection\n",
    "        poly = df[df[\"geometry\"].apply(lambda x: x.contains(reordered_point))]\n",
    "        \n",
    "        self.results = []\n",
    "        for e in data:\n",
    "            if \"lon\" in e and \"lat\" in e and e[\"lon\"] is not None and e[\"lat\"] is not None:\n",
    "                reordered_coords = Point(e[\"lon\"],e[\"lat\"])\n",
    "                if any(poly[\"geometry\"].apply(lambda x: x.contains(reordered_coords))):\n",
    "                    self.results.append(e)\n",
    "        return poly\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def no_duplicates(self,dict_list,new_dicts,key):\n",
    "        for e in new_dicts:\n",
    "            #if the item to add doesnt have the relevant key, put it into results list\n",
    "            if key not in e:\n",
    "                dict_list.append(e)\n",
    "                continue\n",
    "            #if its false that the new item has the same value as an already collected dict, add new item \n",
    "            if not any(e.get(key) == d.get(key) for d in dict_list):\n",
    "                dict_list.append(e)\n",
    "        return dict_list\n",
    "    \n",
    "    @abstractmethod\n",
    "    def retrieve_by_id(self,Client,client_str,db_str,coll_str,batch_ids):\n",
    "        self.connect_db(Client,client_str,db_str,coll_str)\n",
    "        self.data = [e for e in self.collection.find({\"_id\":{\"$in\": batch_ids}})]\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def popupStr_generator(self, df_row):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def tooltip_generator(self,df_row):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def gestalte_map(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def orderly_output(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSM_queryer(DBHandlers):\n",
    "\n",
    "    def connect_db(self,Client=MongoClient,client_str='mongodb://localhost:27017', db_str='webscraping_dataLabKiel', coll_str='osm_pois'):\n",
    "        return super().connect_db(Client,client_str,db_str,coll_str)\n",
    "\n",
    "\n",
    "    def design_query_dict(self,input):\n",
    "        query_terms = []\n",
    "\n",
    "        if \"what\" in input.keys():\n",
    "            for val in input[\"what\"]:\n",
    "                query_terms.append({\"name\":{ \"$regex\": rf\"^{val}\", \"$options\": \"i\" }})\n",
    "                query_terms.append({\"amenity\": { \"$regex\": rf\"^{val}\", \"$options\": \"i\" }})\n",
    "\n",
    "        if \"all\" in input.keys():\n",
    "            query_terms = super().design_query_dict()\n",
    "\n",
    "\n",
    "        if \"by_ids\" in input.keys():\n",
    "            query_terms.append({\"_id\":{\"$in\": input[\"by_ids\"]}})\n",
    "\n",
    "        #for returning nothing\n",
    "        if query_terms == []:\n",
    "            query_terms.append({\"_id\":\"thisisanimpossibleid\"}) #so that if nothing is entered nothing will be returned instead of everything\n",
    "                \n",
    "\n",
    "        self.query_dict = {\"$or\":query_terms}\n",
    "\n",
    "\n",
    "    def retrieve_data(self, **kwargs):\n",
    "        return super().retrieve_data()\n",
    "\n",
    "\n",
    "    def check_click_radius(self, click_point, radius, data):\n",
    "        return super().check_click_radius(click_point, radius, data)\n",
    "    \n",
    "\n",
    "    def no_duplicates(self, dict_list, new_dicts, key):\n",
    "        return super().no_duplicates(dict_list, new_dicts, key)\n",
    "\n",
    "\n",
    "    def popupStr_generator(self, df_row):\n",
    "        try:\n",
    "            name = f\"<b>{df_row['name']}</b><br><br>\"\n",
    "            amenity = f\"<i>amenity:</i>: {df_row['amenity']}\"\n",
    "            pps = name + amenity\n",
    "            return pps\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def tooltip_generator(self,row):\n",
    "        tts = \"\"\n",
    "        try:\n",
    "            tts = row['name']\n",
    "            return tts\n",
    "        except:\n",
    "            pass\n",
    "        return tts\n",
    "\n",
    "    def gestalte_map(self,map,data):\n",
    "        poi_df = pd.DataFrame(data) \n",
    "        try:    \n",
    "            poi_df[\"lat\"] = pd.to_numeric(poi_df[\"lat\"])\n",
    "            poi_df[\"lon\"] = pd.to_numeric(poi_df[\"lon\"])\n",
    "            #poi_df.dropna(subset=[\"lat\",\"lon\"],inplace=True)\n",
    "\n",
    "            for _, row in poi_df.iterrows():\n",
    "                folium.Marker(\n",
    "                    location=[row['lat'], row['lon']],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"gray\")\n",
    "                ).add_to(map)\n",
    "            return map\n",
    "        except:\n",
    "            #print(\"no map available due to e.g. naming errors\")\n",
    "            return map\n",
    "        \n",
    "    def display_output(self,map,data):\n",
    "        self.gestalte_map(map=map,data=data)\n",
    "\n",
    "    def click_polygon(self, click_point, data):\n",
    "        return super().click_polygon(click_point, data)\n",
    "    \n",
    "    def plot_polygon(self,polygons,map):\n",
    "        #add county area\n",
    "        gdf = gpd.GeoDataFrame(polygons, geometry='geometry')\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "        for _,row in gdf.iterrows():\n",
    "            sim_geo = gpd.GeoSeries(row[\"geometry\"]).simplify(tolerance=0.001)\n",
    "            geo_j = sim_geo.to_json()\n",
    "            geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"lightgray\"})\n",
    "            folium.Popup(row[\"name\"]).add_to(geo_j)\n",
    "            geo_j.add_to(map)\n",
    "\n",
    "        #add rent markers\n",
    "        self.display_output(map=map,data=self.results)\n",
    "\n",
    "        return map\n",
    "\n",
    "\n",
    "    def orderly_output(self, data):\n",
    "        output = []\n",
    "        for df_row in data:\n",
    "            doc = {\"name\":df_row['name'], \n",
    "                   \"amenity\":df_row['amenity']}\n",
    "            output.append(doc)\n",
    "        return output \n",
    "    \n",
    "    def retrieve_by_id(self, Client, client_str, db_str, coll_str, batch_ids):\n",
    "        return super().retrieve_by_id(Client, client_str, db_str, coll_str, batch_ids)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YELLOW PAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YP_queryer(DBHandlers):\n",
    "\n",
    "    def connect_db(self,Client=MongoClient,client_str='mongodb://localhost:27017', db_str='sh_data_collection', coll_str='yp_kiel'):\n",
    "        return super().connect_db(Client,client_str,db_str,coll_str)\n",
    "\n",
    "    def design_query_dict(self, input):\n",
    "        query_terms = []\n",
    "\n",
    "        if \"what\" in input.keys():\n",
    "                for val in input[\"what\"]:\n",
    "                        query_terms.append({\"name\":{ \"$regex\": rf\"^{val}\", \"$options\": \"i\" }})\n",
    "                        query_terms.append({\"keywords\":{ \"$regex\": rf\"^{val}\", \"$options\": \"i\" }})\n",
    "\n",
    "        if \"all\" in input.keys():\n",
    "              query_terms = super().design_query_dict()\n",
    "\n",
    "        if \"by_ids\" in input.keys():\n",
    "            query_terms.append({\"_id\":{\"$in\": input[\"by_ids\"]}})\n",
    "\n",
    "        if query_terms == []:\n",
    "                query_terms.append({\"_id\":\"thisisanimpossibleid\"}) #so that if nothing is entered nothing will be returned instead of everything\n",
    "                \n",
    "        self.query_dict = {\"$or\":query_terms}\n",
    "    \n",
    "    def retrieve_data(self):\n",
    "        self.data = [elem for elem in self.collection.find(self.query_dict)]\n",
    "\n",
    "    def time_check(self,time):\n",
    "        mapping = {\"Mo\": [\"Montag\", \"montag\", \"Mo\", \"mo\", \"Monday\", \"monday\"],\n",
    "                    \"Di\": [\"Dienstag\", \"dienstag\", \"Tu\", \"tu\", \"Tuesday\", \"tuesday\"],\n",
    "                    \"Mi\": [\"Mittwoch\", \"mittwoch\", \"We\", \"we\", \"Wednesday\", \"wednesday\"],\n",
    "                    \"Do\": [\"Donnerstag\", \"donnerstag\", \"Th\", \"th\", \"Thursday\", \"thursday\"],\n",
    "                    \"Fr\": [\"Freitag\", \"freitag\", \"Fr\", \"fr\", \"Friday\", \"friday\"],\n",
    "                    \"Sa\": [\"Samstag\", \"samstag\", \"Sa\", \"sa\", \"Saturday\", \"saturday\"],\n",
    "                    \"So\": [\"Sonntag\", \"sonntag\", \"Su\", \"su\", \"Sunday\", \"sunday\"],\n",
    "                }\n",
    "        for k,v in mapping.items():\n",
    "            if time in v:\n",
    "                return k\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    #add this!!!\n",
    "    def within_time(self,data,date):\n",
    "        if date==\"today\":\n",
    "            date = pd.to_datetime(date,dayfirst=True).date() \n",
    "            #date = date.strftime(\"%Y-%m-%d\")  \n",
    "            date = date.strftime(\"%A\") #yields weekday\n",
    "        elif date == \"tomorrow\":\n",
    "            date = pd.to_datetime(\"today\").date()\n",
    "            date = date + timedelta(days=1)\n",
    "            #date = date.strftime(\"%Y-%m-%d\")  \n",
    "            date = date.strftime(\"%A\")\n",
    "        else:\n",
    "            try:\n",
    "                date = pd.to_datetime(date,dayfirst=True).date() #just make normal string date into correct format\n",
    "                date = date.strftime(\"%A\") #but still get weekday\n",
    "            except ValueError:\n",
    "                pass #if its not a date string, then maybe its like monday etc already\n",
    "        time = self.time_check(date) #now get format to check opening hours, so Mo, Di, Mi etc\n",
    "        results = []\n",
    "        for e in data:\n",
    "            opening_hours = e.get(\"openingHours\")\n",
    "            if opening_hours is not None:\n",
    "                if any([k for k in opening_hours if time in k]):\n",
    "                    results.append(e)\n",
    "            else:\n",
    "                #results.append(e)\n",
    "                pass\n",
    "        self.results = results\n",
    "        return results\n",
    "\n",
    "\n",
    "    def check_click_radius(self, click_point, radius, data):\n",
    "        return super().check_click_radius(click_point, radius, data)\n",
    "    \n",
    "    \n",
    "    def no_duplicates(self, dict_list, new_dicts, key):\n",
    "        return super().no_duplicates(dict_list, new_dicts, key)\n",
    "\n",
    "\n",
    "    # PLOTS\n",
    "    def popupStr_generator(self, df_row):\n",
    "        try:\n",
    "            name = f\"<b>{df_row['name']}</b><br><br>\"\n",
    "            link = f\"<i>link:</i>: <a href='{df_row['sameAs']}'>{df_row['sameAs']}</a><br>\"\n",
    "            tel = f\"<i>tel.:</i> {df_row['telephone']}<br>\"\n",
    "            address = df_row[\"address\"]\n",
    "            try:\n",
    "                address = address[\"streetAddress\"] + \", \" + address[\"postalCode\"] + \", \" + address[\"addressLocality\"]\n",
    "            except:\n",
    "                pass\n",
    "            addr = f\"<i>address:</i> {address}<br>\"\n",
    "            pps = name + link + tel + addr \n",
    "            return pps\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def tooltip_generator(self,row):\n",
    "        tts = \"\"\n",
    "        try:\n",
    "            tts = row['name']\n",
    "            return tts\n",
    "        except:\n",
    "            pass\n",
    "        return tts\n",
    "\n",
    "    def gestalte_map(self,map,data):\n",
    "        poi_df = pd.DataFrame(data) \n",
    "        try:    \n",
    "            poi_df[\"lat\"] = pd.to_numeric(poi_df[\"lat\"])\n",
    "            poi_df[\"lon\"] = pd.to_numeric(poi_df[\"lon\"])\n",
    "            #poi_df.dropna(subset=[\"lat\",\"lon\"],inplace=True)\n",
    "\n",
    "            for _, row in poi_df.iterrows():\n",
    "                folium.Marker(\n",
    "                    location=[row['lat'], row['lon']],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"beige\")\n",
    "                ).add_to(map)\n",
    "            return map\n",
    "        except:\n",
    "            #print(\"no map available due to e.g. naming errors\")\n",
    "            return map\n",
    "            \n",
    "    def display_output(self,map,data):\n",
    "        self.gestalte_map(map=map,data=data) \n",
    "\n",
    "    def click_polygon(self, click_point, data):\n",
    "         return super().click_polygon(click_point, data)\n",
    "\n",
    "    def plot_polygon(self,polygons,map):\n",
    "        #add county area\n",
    "        gdf = gpd.GeoDataFrame(polygons, geometry='geometry')\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "        for _,row in gdf.iterrows():\n",
    "            sim_geo = gpd.GeoSeries(row[\"geometry\"]).simplify(tolerance=0.001)\n",
    "            geo_j = sim_geo.to_json()\n",
    "            geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"lightgrey\"})\n",
    "            folium.Popup(row[\"name\"]).add_to(geo_j)\n",
    "            geo_j.add_to(map)\n",
    "\n",
    "        #add rent markers\n",
    "        self.display_output(map=map,data=self.results)\n",
    "\n",
    "        return map\n",
    "\n",
    "    def orderly_output(self, data):\n",
    "        output = []\n",
    "        for df_row in data:\n",
    "            address = df_row[\"address\"]\n",
    "            try:\n",
    "                nice_address = address[\"streetAddress\"] + \", \" + address[\"postalCode\"] + \", \" + address[\"addressLocality\"]\n",
    "                address = f\"<i>address:</i> {nice_address}<br>\"\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                name = df_row['name']\n",
    "            except:\n",
    "                name = None\n",
    "            try:\n",
    "                tel = df_row['telephone']\n",
    "            except:\n",
    "                tel = None\n",
    "            try:\n",
    "                hours = df_row[\"openingHours\"]\n",
    "            except:\n",
    "                hours = None\n",
    "\n",
    "            doc = {\"name\":name, \n",
    "                   \"tel\":tel,\n",
    "                   \"address\":address,\n",
    "                   \"open\":hours}\n",
    "            output.append(doc)\n",
    "        return output \n",
    "    \n",
    "\n",
    "    def retrieve_by_id(self, Client, client_str, db_str, coll_str, batch_ids):\n",
    "        return super().retrieve_by_id(Client, client_str, db_str, coll_str, batch_ids)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RENT_queryer(DBHandlers):\n",
    "\n",
    "    def connect_db(self,Client=MongoClient,client_str='mongodb://localhost:27017', db_str='webscraping_dataLabKiel', coll_str='avg_rent'):\n",
    "        return super().connect_db(Client,client_str,db_str,coll_str)\n",
    "\n",
    "    def design_query_dict(self, input):\n",
    "        query_terms = []\n",
    "\n",
    "        if \"rent\" in input.keys():\n",
    "                #query_terms = super().design_query_dict() #get everything\n",
    "                query_terms = [{\"collected\":\"True\"}]\n",
    "\n",
    "        if \"what\" in input.keys():\n",
    "            for val in input[\"what\"]:\n",
    "                if val in [\"rent\",\"rents\",\"miete\",\"Miete\"]:\n",
    "                    query_terms = query_terms = [{\"collected\":\"True\"}]\n",
    "\n",
    "        if \"all\" in input.keys():\n",
    "              #query_terms = super().design_query_dict()\n",
    "              query_terms = [{\"collected\":\"True\"}]\n",
    "\n",
    "        if \"by_ids\" in input.keys():\n",
    "            query_terms.append({\"_id\":{\"$in\": input[\"by_ids\"]}})\n",
    "\n",
    "        if query_terms == []:\n",
    "                query_terms.append({\"_id\":\"thisisanimpossibleid\"}) #so that if nothing is entered nothing will be returned instead of everything\n",
    "                \n",
    "        self.query_dict = {\"$or\":query_terms}\n",
    "    \n",
    "\n",
    "    def retrieve_data(self):\n",
    "        self.data = [elem for elem in self.collection.find(self.query_dict)]\n",
    "\n",
    "    \n",
    "    def check_click_radius(self, click_point, radius, data):\n",
    "        return super().check_click_radius(click_point, radius, data)\n",
    "\n",
    "\n",
    "    def no_duplicates(self, dict_list, new_dicts, key):\n",
    "        return super().no_duplicates(dict_list, new_dicts, key)\n",
    "\n",
    "\n",
    "    def tooltip_generator(self,row):\n",
    "        tts = \"\"\n",
    "        try: \n",
    "            tts = f\"{row[\"average_rent\"]}€ m²\"\n",
    "            return tts\n",
    "        except:\n",
    "            pass\n",
    "        return tts\n",
    "\n",
    "    def popupStr_generator(self,df_row):\n",
    "        try:\n",
    "            if df_row[\"Landkreis\"] != []:\n",
    "                name = f\"<b>{df_row['Landkreis']}</b><br><br>\"\n",
    "            else:\n",
    "                name = f\"<b>{df_row['Stadt']}</b><br><br>\"\n",
    "            plz = f\"<i>postcode:</i> {df_row['PLZ']}<br>\"\n",
    "            rent = f\"<i>rent:</i> {df_row['average_rent']}€ per m²\"\n",
    "            pps = name + plz + rent\n",
    "            return pps\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #so make sure data has no duplicates and all the naming is the same\n",
    "    def gestalte_map(self,map,data):\n",
    "        poi_df = pd.DataFrame(data) #compile business sample into df\n",
    "        try:    \n",
    "            median_rent = poi_df.average_rent.mean()\n",
    "            poi_df[\"rent_ratio\"] = poi_df.average_rent.apply(lambda x: \"high\" if x > median_rent else \"low\")\n",
    "            high_rents = poi_df[poi_df[\"rent_ratio\"]==\"high\"]\n",
    "            for _, row in high_rents.iterrows():\n",
    "                folium.Marker(\n",
    "                    location=[row['lat'], row['lon']],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"lightred\")\n",
    "                ).add_to(map)\n",
    "            low_rents = poi_df[poi_df[\"rent_ratio\"]==\"low\"]\n",
    "            for _, row in low_rents.iterrows():\n",
    "                folium.Marker(\n",
    "                    location=[row['lat'], row['lon']],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"lightblue\")\n",
    "                ).add_to(map)\n",
    "            return map\n",
    "        except:\n",
    "            #print(\"no map available due to e.g. naming errors\")\n",
    "            return map\n",
    "\n",
    "            \n",
    "    def display_output(self,map,data):\n",
    "        self.gestalte_map(map=map,data=data) #z is level of zoom\n",
    "\n",
    "    def click_polygon(self, click_point, data):\n",
    "        return super().click_polygon(click_point, data)\n",
    "    \n",
    "    def plot_polygon(self,polygons,map):\n",
    "        #add county area\n",
    "        gdf = gpd.GeoDataFrame(polygons, geometry='geometry')\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "        for _,row in gdf.iterrows():\n",
    "            sim_geo = gpd.GeoSeries(row[\"geometry\"]).simplify(tolerance=0.001)\n",
    "            geo_j = sim_geo.to_json()\n",
    "            geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"lightgray\"})\n",
    "            folium.Popup(row[\"name\"]).add_to(geo_j)\n",
    "            geo_j.add_to(map)\n",
    "\n",
    "        #add rent markers\n",
    "        self.display_output(map=map,data=self.results)\n",
    "\n",
    "        return map\n",
    "        \n",
    "\n",
    "\n",
    "    def orderly_output(self, data):\n",
    "        output = []\n",
    "        for df_row in data:\n",
    "            doc = {\"county\":df_row[\"Landkreis\"],\n",
    "                   \"city\":df_row['Stadt'],\n",
    "                   \"postcode\":df_row['PLZ'],\n",
    "                   \"avgerage rent\":df_row['average_rent']}\n",
    "            output.append(doc)\n",
    "        return output \n",
    "    \n",
    "\n",
    "    def retrieve_by_id(self, Client, client_str, db_str, coll_str, batch_ids):\n",
    "        return super().retrieve_by_id(Client, client_str, db_str, coll_str, batch_ids)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVENT_queryer(DBHandlers):\n",
    "\n",
    "    def connect_db(self,Client=MongoClient,client_str='mongodb://localhost:27017', db_str='webscraping_dataLabKiel', coll_str='event_data'):\n",
    "        return super().connect_db(Client,client_str,db_str,coll_str)\n",
    "\n",
    "    def design_query_dict(self, input):\n",
    "        query_terms = []\n",
    "\n",
    "        if \"what\" in input.keys():\n",
    "            for val in input[\"what\"]:\n",
    "                query_terms.append({\"title\":{ \"$regex\": rf\"^{val}\", \"$options\": \"i\" }})\n",
    "                query_terms.append({\"categories\":{ \"$regex\": rf\"^{val}\", \"$options\": \"i\" }})\n",
    "                if val in [\"event\",\"events\",\"Event\",\"Events\"]:\n",
    "                    query_terms = super().design_query_dict()\n",
    "\n",
    "\n",
    "        if \"event\" in input.keys():\n",
    "            if input[\"event\"] == True:\n",
    "                query_terms = super().design_query_dict()\n",
    "            #else:\n",
    "                #query_terms = query_terms = super().design_query_dict()\n",
    "                #check if collected events are at the relevant time or sth\n",
    "\n",
    "        if \"all\" in input.keys():\n",
    "            query_terms = super().design_query_dict()\n",
    "\n",
    "        if \"by_ids\" in input.keys():\n",
    "            query_terms.append({\"_id\":{\"$in\": input[\"by_ids\"]}})\n",
    "\n",
    "        if query_terms == []:\n",
    "            query_terms.append({\"_id\":\"thisisanimpossibleid\"}) #so that if nothing is entered nothing will be returned instead of everything\n",
    "                \n",
    "        self.query_dict = {\"$or\":query_terms}\n",
    "    \n",
    "\n",
    "    def retrieve_data(self):\n",
    "        self.data = [elem for elem in self.collection.find(self.query_dict)]\n",
    "\n",
    "    \n",
    "    def check_click_radius(self, click_point, radius, data):\n",
    "        return super().check_click_radius(click_point, radius, data)\n",
    "\n",
    "\n",
    "    def no_duplicates(self, dict_list, new_dicts, key):\n",
    "        return super().no_duplicates(dict_list, new_dicts, key)\n",
    "    \n",
    "    def within_time(self,data,date):\n",
    "        if date==\"today\":\n",
    "            date = pd.to_datetime(date,dayfirst=True).date() \n",
    "            #date = date.strftime(\"%Y-%m-%d\")  \n",
    "        elif date == \"tomorrow\":\n",
    "            date = pd.to_datetime(\"today\").date()\n",
    "            date = date + timedelta(days=1)\n",
    "            #date = date.strftime(\"%Y-%m-%d\")  \n",
    "        else:\n",
    "            try:\n",
    "                date = pd.to_datetime(date,dayfirst=True).date()\n",
    "            except ValueError:\n",
    "                #print(\"check your time format\")\n",
    "                pass\n",
    "        results = []\n",
    "        for e in data:\n",
    "            if e.get(\"timeIntervals\") is not None:\n",
    "                ongoing = e.get(\"timeIntervals\")\n",
    "                ongoing = ongoing[0]\n",
    "                #date = pd.to_datetime(date,dayfirst=True,format=\"%Y-%m-%d\").date()\n",
    "                #print(type(start),type(end),type(date))\n",
    "                start, end = pd.to_datetime(ongoing[\"start\"]).date(), pd.to_datetime(ongoing[\"end\"]).date()\n",
    "                if start <= date <= end:\n",
    "                    results.append(e)\n",
    "                else:\n",
    "                    #results.append(e)\n",
    "                    pass\n",
    "        self.results = results\n",
    "        return results\n",
    "    \n",
    "\n",
    "    # PLOTS\n",
    "    def popupStr_generator(self, df_row):\n",
    "        try:\n",
    "            name = f\"<b>{df_row['title']}</b><br><br>\"\n",
    "            link = f\"<i>link:</i>: <a href='{df_row['source.url']}'>{df_row['source.url']}</a><br>\"\n",
    "            tel = f\"<i>tel.:</i> {df_row['phone']}<br>\"\n",
    "            try:\n",
    "                street = df_row[\"street\"]\n",
    "            except:\n",
    "                street = \"\"\n",
    "            try:\n",
    "                city = df_row[\"city\"] \n",
    "            except:\n",
    "                city = \"\"\n",
    "            try:\n",
    "                zip = df_row[\"zip\"]\n",
    "            except:\n",
    "                zip = None\n",
    "            nice_addr = street + \", \" + city + \", \" + zip\n",
    "            addr = f\"<i>address:</i> {nice_addr}<br>\"\n",
    "            event_type = df_row['categories']\n",
    "            separator = \", \" \n",
    "            event_cat = separator.join(event_type)\n",
    "            cat = f\"<i>event type:</i> {event_cat}<br>\"\n",
    "            pps = name + link + tel + cat + addr \n",
    "            return pps\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def tooltip_generator(self,row):\n",
    "        tts = \"\"\n",
    "        try:\n",
    "            tts = row['title']\n",
    "            return tts\n",
    "        except:\n",
    "            pass\n",
    "        return tts\n",
    "\n",
    "    def gestalte_map(self,map,data):\n",
    "        poi_df = pd.DataFrame(data) \n",
    "        try:    \n",
    "            poi_df[\"lat\"] = pd.to_numeric(poi_df[\"lat\"])\n",
    "            poi_df[\"lon\"] = pd.to_numeric(poi_df[\"lon\"])\n",
    "            #poi_df.dropna(subset=[\"lat\",\"lon\"],inplace=True)\n",
    "\n",
    "            for _, row in poi_df.iterrows():\n",
    "                folium.Marker(\n",
    "                    location=[row['lat'], row['lon']],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"purple\")\n",
    "                ).add_to(map)\n",
    "            return map\n",
    "        except:\n",
    "            #print(\"no map available due to e.g. naming errors\")\n",
    "            return map\n",
    "            \n",
    "    def display_output(self,map,data):\n",
    "        self.gestalte_map(map=map,data=data) \n",
    "\n",
    "\n",
    "    def click_polygon(self, click_point, data):\n",
    "        return super().click_polygon(click_point, data)\n",
    "    \n",
    "    def plot_polygon(self,polygons,map):\n",
    "        #add county area\n",
    "        gdf = gpd.GeoDataFrame(polygons, geometry='geometry')\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "        for _,row in gdf.iterrows():\n",
    "            sim_geo = gpd.GeoSeries(row[\"geometry\"]).simplify(tolerance=0.001)\n",
    "            geo_j = sim_geo.to_json()\n",
    "            geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"lightgray\"})\n",
    "            folium.Popup(row[\"name\"]).add_to(geo_j)\n",
    "            geo_j.add_to(map)\n",
    "\n",
    "        #add rent markers\n",
    "        self.display_output(map=map,data=self.results)\n",
    "\n",
    "        return map\n",
    "\n",
    "    def orderly_output(self, data):\n",
    "        output = []\n",
    "        for df_row in data:\n",
    "            try:\n",
    "                street = df_row[\"street\"]\n",
    "            except:\n",
    "                street = \"\"\n",
    "            try:\n",
    "                city = df_row[\"city\"] \n",
    "            except:\n",
    "                city = \"\"\n",
    "            try:\n",
    "                zip = df_row[\"zip\"]\n",
    "            except:\n",
    "                zip = None\n",
    "            nice_addr = street + \", \" + city + \", \" + zip\n",
    "            doc = {\"name\":df_row[\"name\"],\n",
    "                   \"tel\":df_row['phone'],\n",
    "                   \"address\":nice_addr,\n",
    "                   \"time\":df_row['timeIntervals']}\n",
    "            output.append(doc)\n",
    "        return output \n",
    "    \n",
    "\n",
    "    def retrieve_by_id(self, Client, client_str, db_str, coll_str, batch_ids):\n",
    "        return super().retrieve_by_id(Client, client_str, db_str, coll_str, batch_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NATURAL AREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIGITIZEDPLANET_queryer(DBHandlers):\n",
    "\n",
    "\n",
    "    #CONNECT TO DB - COLLECTION\n",
    "    def connect_db(self,Client=MongoClient,client_str='mongodb://localhost:27017', db_str='webscraping_dataLabKiel', coll_str='digitized_planet_v2'):\n",
    "        return super().connect_db(Client,client_str,db_str,coll_str)\n",
    "\n",
    "    #GET QUERY DICTIONARY FOR SEARCH\n",
    "    def design_query_dict(self, input):\n",
    "        query_terms = []\n",
    "\n",
    "        if \"what\" in input.keys():\n",
    "            for e in input[\"what\"]:\n",
    "                if e in [\"nature\",\"Natur\",\"natural area\",\"protected area\",\"naturschutzgebiet\",\"park\"]:\n",
    "                    query_terms = super().design_query_dict()\n",
    "\n",
    "        if \"all\" in input.keys():\n",
    "            query_terms = super().design_query_dict()\n",
    "\n",
    "        if \"by_ids\" in input.keys():\n",
    "            query_terms.append({\"_id\":{\"$in\": input[\"by_ids\"]}})\n",
    "\n",
    "        if query_terms == []:\n",
    "            query_terms.append({\"_id\":\"thisisanimpossibleid\"}) #so that if nothing is entered nothing will be returned instead of everything\n",
    "                \n",
    "        self.query_dict = {\"$or\":query_terms}\n",
    "    \n",
    "    #RETRIEVE DATA BASED ON QUERY DICT\n",
    "    def retrieve_data(self):\n",
    "        self.data = [elem for elem in self.collection.find(self.query_dict)]\n",
    "\n",
    "    \n",
    "    #FILTER DATA BASED ON`RADIUS`\n",
    "    def check_click_radius(self, click_point, radius, data):\n",
    "        return super().check_click_radius(click_point, radius, data)\n",
    "    \n",
    "\n",
    "    def no_duplicates(self, dict_list, new_dicts, key):\n",
    "        return super().no_duplicates(dict_list, new_dicts, key)\n",
    "\n",
    "\n",
    "    # PLOTS\n",
    "    def popupStr_generator(self, df_row):\n",
    "        try:\n",
    "            name = f\"<b>{df_row['name']}</b><br><br>\"\n",
    "            area = f\"<i>area in m²:</i> {df_row['area']}<br>\"\n",
    "            geom_s = f\"<i>source:</i> {df_row['geometry_source']}<br>\"\n",
    "            pps = name + area + geom_s\n",
    "            return pps\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def tooltip_generator(self,row):\n",
    "        tts = \"\"\n",
    "        try:\n",
    "            tts = row['name']\n",
    "            return tts\n",
    "        except:\n",
    "            pass\n",
    "        return tts\n",
    "\n",
    "    def gestalte_map(self,map,data):\n",
    "        poi_df = pd.DataFrame(data) \n",
    "        try:    \n",
    "            for _, row in poi_df.iterrows():\n",
    "                folium.Marker(\n",
    "                    location=[row['lat'], row['lon']],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"darkblue\")\n",
    "                ).add_to(map)\n",
    "            return map\n",
    "        except:\n",
    "            #print(\"no map available due to e.g. naming errors\")\n",
    "            return map\n",
    "                    \n",
    "\n",
    "    def click_polygon(self, click_point, data):\n",
    "        return super().click_polygon(click_point, data)\n",
    "\n",
    "    def plot_area_polygon(self,map,data):\n",
    "        try:\n",
    "            poi_df = pd.DataFrame(data)\n",
    "            poi_df[\"geometry\"] = poi_df['geometry'].apply(shape)\n",
    "            gdf = gpd.GeoDataFrame(poi_df, geometry='geometry')\n",
    "            gdf.set_crs(epsg=4326, inplace=True)\n",
    "            for _,row in gdf.iterrows():\n",
    "                sim_geo = gpd.GeoSeries(row[\"geometry\"]).simplify(tolerance=0.001)\n",
    "                geo_j = sim_geo.to_json()\n",
    "                geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"darkblue\"})\n",
    "                folium.Popup(self.popupStr_generator(row)).add_to(geo_j)\n",
    "                geo_j.add_to(map)\n",
    "            \n",
    "            gdf = gdf.to_crs(epsg=2263)\n",
    "            gdf[\"centroid\"] = gdf.centroid.to_crs(epsg=4326)\n",
    "            for _, row in gdf.iterrows():\n",
    "                lat = row[\"centroid\"].y\n",
    "                lon = row[\"centroid\"].x\n",
    "                folium.Marker(\n",
    "                    location=[lat, lon],\n",
    "                    popup=self.popupStr_generator(row),\n",
    "                    tooltip=self.tooltip_generator(row),\n",
    "                    icon=folium.Icon(color=\"darkblue\")\n",
    "                ).add_to(map)\n",
    "            return map\n",
    "        except:\n",
    "            return map\n",
    "\n",
    "    def plot_polygon(self,polygons,map):\n",
    "        #add county area\n",
    "        gdf = gpd.GeoDataFrame(polygons, geometry='geometry')\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "        for _,row in gdf.iterrows():\n",
    "            sim_geo = gpd.GeoSeries(row[\"geometry\"]).simplify(tolerance=0.001)\n",
    "            geo_j = sim_geo.to_json()\n",
    "            geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"lightgray\"})\n",
    "            folium.Popup(row[\"name\"]).add_to(geo_j)\n",
    "            geo_j.add_to(map)\n",
    "\n",
    "        #add areas & markers\n",
    "        self.plot_area_polygon(map=map,data=self.results)\n",
    "\n",
    "        return map\n",
    "    \n",
    "    def display_output(self,map,data):\n",
    "        self.plot_area_polygon(map=map,data=data) \n",
    "        #bzw self.gestalte_map(map=map,data=data) \n",
    "\n",
    "\n",
    "    def orderly_output(self, data):\n",
    "        output = []\n",
    "        for df_row in data:\n",
    "            doc = {\"name\":df_row[\"name\"],\n",
    "                   \"area\":df_row['area'],\n",
    "                   \"source\":df_row['geometry_source']}\n",
    "            output.append(doc)\n",
    "        return output \n",
    "    \n",
    "    def retrieve_by_id(self, Client, client_str, db_str, coll_str, batch_ids):\n",
    "        return super().retrieve_by_id(Client, client_str, db_str, coll_str, batch_ids)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nlp search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP_search(DBHandlers):\n",
    "\n",
    "\n",
    "    #CONNECT TO DB - COLLECTION\n",
    "    def connect_db(self,Client,embedding,collection,path):\n",
    "        vectordb = Client(\n",
    "            collection_name=collection,\n",
    "            persist_directory=path,\n",
    "            embedding_function=embedding\n",
    "        )\n",
    "        self.retriever = vectordb.as_retriever(search_kwargs=dict(k=20))\n",
    "        return vectordb\n",
    "\n",
    "    \n",
    "    #RETRIEVE DATA BASED ON QUERY DICT\n",
    "    def retrieve_data(self,input):\n",
    "        #print(self.retriever)\n",
    "        self.data = self.retriever.invoke(input) #HERE LIES THE ISSUE?\n",
    "        #print(self.data)\n",
    "        batch_ids = [ObjectId(r.metadata[\"mongo_id\"]) for r in self.data]\n",
    "        return batch_ids\n",
    "    \n",
    "        #GET QUERY DICTIONARY FOR SEARCH\n",
    "    def design_query_dict(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    #FILTER DATA BASED ON`RADIUS`\n",
    "    def check_click_radius(self, click_point, radius, data):\n",
    "        pass\n",
    "    \n",
    "    def no_duplicates(self, dict_list, new_dicts, key):\n",
    "        pass\n",
    "\n",
    "    def popupStr_generator(self, df_row):\n",
    "        pass\n",
    "\n",
    "    def tooltip_generator(self, df_row):\n",
    "        pass\n",
    "\n",
    "    def gestalte_map(self,map,data):\n",
    "        pass\n",
    "                    \n",
    "    def click_polygon(self, click_point, data):\n",
    "        pass\n",
    "\n",
    "    def plot_area_polygon(self,map,data):\n",
    "        pass\n",
    "\n",
    "    def plot_polygon(self,polygons,map):\n",
    "        pass\n",
    "    \n",
    "    def display_output(self,map,data):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def orderly_output(self, data):\n",
    "        pass\n",
    "    \n",
    "    def retrieve_by_id(self, Client, client_str, db_str, coll_str, batch_ids):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTPUT MANAGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputManager():\n",
    "\n",
    "    #make function which integrated but doesnt return data from all data bases!!!\n",
    "    def disambiguate(self,queriers):    \n",
    "        threshold = 80 #of similarity, selected by just trying it out\n",
    "        temp = []\n",
    "\n",
    "        #go through the returned (no duplicate) result list of every querier\n",
    "        for q in queriers:\n",
    "            querier_results = q.results #get data for the querier\n",
    "            q.results = [] #empty slate for querier.results\n",
    "\n",
    "            #as long as theres still names to check\n",
    "            while querier_results != []:\n",
    "                elem = querier_results.pop()\n",
    "                try:\n",
    "                    name = elem[\"name\"]\n",
    "                    possible_double = [k for k in temp if fuzz.token_set_ratio(name,k.get(\"name\")) >= threshold] #retrieve similar names from temp result list\n",
    "                    if len(possible_double) >= 1: #if some similar name(s) found\n",
    "                        elem_loc = (elem[\"lat\"],elem[\"lon\"]) #get coordinates of original point which we want to add\n",
    "                        the_same = False #assume they are not the same location\n",
    "                        for pos_doub in possible_double:\n",
    "                            pos_doub_loc = (pos_doub[\"lat\"],pos_doub[\"lon\"]) #get coordinates from matches from temporary result list\n",
    "                            if geodesic(elem_loc,pos_doub_loc).km < 0.1: # if it turns out they are in same locations, so if they are more less 100m apart\n",
    "                                the_same = True # flag: okay so actually we found a match, so something with a similar name less than 100 m away\n",
    "                        if the_same==False: # only if we didnt find anything simlar at all\n",
    "                            temp.append(elem) #append to temporary checking list\n",
    "                            q.results.append(elem) #add to collection specific result bucket so we can pass it again to database handler for output\n",
    "                    else: #if we dont have anything similar (yet) just stick it in there\n",
    "                        temp.append(elem)\n",
    "                        q.results.append(elem)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "\n",
    "    #return (filtered) search results \n",
    "    def initiate_search(self,Querier,query,key):\n",
    "        q = Querier()\n",
    "        q.connect_db()\n",
    "        q.design_query_dict(query)\n",
    "        q.retrieve_data()\n",
    "        q.results = q.no_duplicates([],q.data,key)\n",
    "        return q\n",
    "    \n",
    "    def unbounded_data(self,q,map):\n",
    "        q.display_output(map=self.map,data=q.results)\n",
    "        return map, q.results\n",
    "    \n",
    "    #get data within a certain radius\n",
    "    def radius_data(self,q,map,point,radius):\n",
    "        q.check_click_radius(click_point=point,radius=radius, data=q.results) \n",
    "        q.display_output(map=self.map,data=q.results)\n",
    "        return map, q.results\n",
    "\n",
    "    #get data within polygon (== county)\n",
    "    def polygon_data(self,q,map,point):\n",
    "        poly = q.click_polygon(click_point=point,data=q.results)\n",
    "        q.plot_polygon(poly,map)\n",
    "        return map, q.results\n",
    "\n",
    "    # area is radius (e.g. 0.5) or \"polygon\"\n",
    "    def process_query_click(self, querier_instance, area, point, map_object):\n",
    "        if area == \"polygon\":\n",
    "            return self.polygon_data(querier_instance, map_object, point)\n",
    "        elif isinstance(area, (int, float)): #is radius essentially\n",
    "            return self.radius_data(querier_instance, map_object, point, area)\n",
    "        else:\n",
    "            return self.unbounded_data(querier_instance, map_object)\n",
    "        \n",
    "\n",
    "    def perform_search(self,**kwargs):\n",
    "        \n",
    "        # click + filter \n",
    "        # click + empty filter: all \n",
    "        # no click + filter (so not area specific, neither radius nor polygon!!!) -> area = None\n",
    "\n",
    "        #if \"query\" in kwargs and \"point\" in kwargs and \"area\" in kwargs:\n",
    "\n",
    "        # SET UP: get arguments\n",
    "        if \"query\" in kwargs and \"point\" in kwargs and \"area\" in kwargs:\n",
    "            query, point, area = kwargs[\"query\"], kwargs[\"point\"], kwargs[\"area\"]\n",
    "            self.map = folium.Map(location=point,zoom_start=8) #one output object of output manager\n",
    "        elif \"query\" in kwargs:\n",
    "            query, point, area = kwargs[\"query\"], None, None\n",
    "            self.map = folium.Map(location=(54.2194,9.6961),zoom_start=6) #one output object of output manager\n",
    "\n",
    "        # out of the query dict get the actual value\n",
    "        time_search = False\n",
    "        if query.get(\"time\") is not None:\n",
    "            time_search = True\n",
    "            time = query.get(\"time\")\n",
    "\n",
    "        \n",
    "        # INSTANTIATE QUERIERS (get data, apply no duplicate, get results per querier)\n",
    "        self.querier_osm = self.initiate_search(OSM_queryer, query=query,key=\"\")\n",
    "        self.querier_yp = self.initiate_search(YP_queryer, query=query,key=\"name\")\n",
    "        self.querier_event = self.initiate_search(EVENT_queryer, query=query,key=\"\")\n",
    "        self.querier_rent = self.initiate_search(RENT_queryer, query=query,key=\"PLZ\")\n",
    "        self.querier_area = self.initiate_search(DIGITIZEDPLANET_queryer, query=query,key=\"name\")\n",
    "\n",
    "        # DISAMBIGUATE ALL DATA BY NAME SIMILARITY AND LOCATION\n",
    "        queriers = [self.querier_yp,self.querier_osm,self.querier_event]\n",
    "        self.disambiguate(queriers)\n",
    "\n",
    "        # NOW CHECK TIMES \n",
    "        if time_search == True:\n",
    "            #for yellow page easy, just check if result of time is helpful\n",
    "            self.querier_yp.results = self.querier_yp.within_time(data=self.querier_yp.results,date=time)\n",
    "            self.querier_event.results = self.querier_event.within_time(data=self.querier_event.results,date=time)\n",
    "            self.querier_event.no_duplicates([],self.querier_event.results,key=\"title\")\n",
    "\n",
    "        # NOW PUT DATA ON MAP\n",
    "        self.map, self.osm_data = self.process_query_click(self.querier_osm, area=area, point=point, map_object=self.map)\n",
    "        self.map, self.yp_data = self.process_query_click(self.querier_yp, area=area, point=point, map_object=self.map)\n",
    "        self.map, self.event_data = self.process_query_click(self.querier_event, area=area, point=point, map_object=self.map)\n",
    "        self.map, self.rent_data = self.process_query_click(self.querier_rent, area=area, point=point, map_object=self.map)\n",
    "        self.map, self.area_data = self.process_query_click(self.querier_area, area=area, point=point, map_object=self.map)\n",
    "\n",
    "        # COMBINE ALL DATA\n",
    "        #for all queriers now! nicefy data\n",
    "        self.nice_data = self.querier_yp.orderly_output(data=self.yp_data) + self.querier_rent.orderly_output(data=self.rent_data) + self.querier_event.orderly_output(data=self.event_data) + self.querier_area.orderly_output(data=self.area_data) + self.querier_osm.orderly_output(data=self.osm_data)\n",
    "        self.data = self.yp_data + self.osm_data + self.event_data + self.rent_data + self.area_data\n",
    "\n",
    "    \n",
    "\n",
    "    def nlp_search(self, **kwargs):\n",
    "        if \"nlp\" in kwargs:\n",
    "            input = kwargs[\"nlp\"]\n",
    "            nlp = NLP_search()\n",
    "            vdb = nlp.connect_db(Chroma,HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2'),\"nlp_search\",r\"C:\\Users\\dorar\\Documents\\kiel\\data_science\\semester_2\\application_projects\\dataLab_kiel\\code\\SH_data_platform\\vector_store\\nlp_search\")\n",
    "            ids = nlp.retrieve_data(input)\n",
    "            query = {\"by_ids\":ids}\n",
    "            self.perform_search(query=query)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [\n",
    "    (54.51450, 8.86610),  # Nordfriesland\n",
    "    (54.17230, 9.03890),  # Dithmarschen\n",
    "    (54.36980, 9.73560),  # Rendsburg-Eckernförde\n",
    "    (54.71020, 9.41230),  # Schleswig-Flensburg\n",
    "    (54.20840, 10.41490), # Plön\n",
    "    (54.17650, 10.93020), # Ostholstein\n",
    "    (53.67620, 9.66230),  # Pinneberg\n",
    "    (53.91540, 10.25580), # Segeberg\n",
    "    (53.70010, 10.39460)  # Stormarn\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
